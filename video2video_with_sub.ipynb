{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 31/78806 [00:07<5:02:51,  4.34it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in output_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 31/78806 [00:39<27:39:49,  1.26s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Đường dẫn tới video của bạn\n",
    "video_path = \"video.mp4\"\n",
    "audio_output_path = \"output_audio.wav\"\n",
    "\n",
    "# Tách âm thanh từ video\n",
    "video_clip = VideoFileClip(video_path)\n",
    "audio_clip = video_clip.audio\n",
    "audio_clip.write_audiofile(audio_output_path, codec=\"pcm_s16le\")  # Lưu âm thanh dưới định dạng WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/code/video2videosub/.venv_/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of Speech2TextForConditionalGeneration were not initialized from the model checkpoint at facebook/s2t-small-librispeech-asr and are newly initialized: ['model.decoder.embed_positions.weights', 'model.encoder.embed_positions.weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtitles saved as output_subtitles.srt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "import srt\n",
    "from datetime import timedelta\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Check if a GPU is available and move the model to GPU if possible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the model and processor\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\").to(device)\n",
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "\n",
    "# Load and resample the audio file to 16,000 Hz\n",
    "audio_path = \"output_audio.wav\"  # Replace with your file path\n",
    "waveform, sample_rate = torchaudio.load(audio_path)\n",
    "if sample_rate != 16000:\n",
    "    waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)\n",
    "\n",
    "# Define chunk size (e.g., 11 seconds per chunk) and prepare for transcription\n",
    "chunk_size = 11 * 16000  # 11 seconds * 16000 samples per second\n",
    "transcriptions = []\n",
    "\n",
    "# Process each chunk separately and record start/end times for SRT\n",
    "segments = []\n",
    "for i in range(0, waveform.size(1), chunk_size):\n",
    "    # Extract chunk of the waveform\n",
    "    chunk = waveform[:, i:i + chunk_size]\n",
    "\n",
    "    # Preprocess the audio chunk\n",
    "    inputs = processor(chunk.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Perform inference on the chunk\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            inputs[\"input_features\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=200,  # Adjust based on your VRAM availability\n",
    "            num_beams=1\n",
    "        )\n",
    "\n",
    "    # Decode the chunk transcription\n",
    "    transcription_chunk = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    transcriptions.append(transcription_chunk)  # Append the text result for the chunk\n",
    "\n",
    "    # Calculate start and end times for SRT\n",
    "    start_time = timedelta(seconds=i / 16000)\n",
    "    end_time = timedelta(seconds=min(i + chunk_size, waveform.size(1)) / 16000)\n",
    "    segments.append(srt.Subtitle(index=len(segments) + 1, start=start_time, end=end_time, content=transcription_chunk))\n",
    "\n",
    "    # Clear memory after each chunk\n",
    "    del inputs, generated_ids\n",
    "    torch.cuda.empty_cache() if device == \"cuda\" else None\n",
    "\n",
    "# Combine all transcriptions and generate SRT content\n",
    "final_transcription = \" \".join(transcriptions)\n",
    "srt_content = srt.compose(segments)\n",
    "\n",
    "# Save the SRT file\n",
    "srt_path = \"output_subtitles.srt\"\n",
    "with open(srt_path, \"w\") as f:\n",
    "    f.write(srt_content)\n",
    "\n",
    "print(\"Subtitles saved as output_subtitles.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "# Integrate subtitles into the video (requires ffmpeg installed)\n",
    "video_path = \"video.mp4\"  # Replace with your video file path\n",
    "output_video_path = \"video_with_subtitles.mp4\"\n",
    "ffmpeg_command = f\"ffmpeg -i {video_path} -vf subtitles={srt_path} {output_video_path}\"\n",
    "\n",
    "import os\n",
    "os.system(ffmpeg_command)\n",
    "\n",
    "print(f\"Final video with subtitles saved as {output_video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
