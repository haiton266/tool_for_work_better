{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./package/certifi-2024.8.30-py3-none-any.whl\n",
      "Processing ./package/charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Processing ./package/filelock-3.16.1-py3-none-any.whl\n",
      "Processing ./package/fsspec-2024.10.0-py3-none-any.whl\n",
      "Processing ./package/huggingface_hub-0.26.2-py3-none-any.whl\n",
      "Processing ./package/idna-3.10-py3-none-any.whl\n",
      "Processing ./package/jinja2-3.1.4-py3-none-any.whl\n",
      "Processing ./package/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Processing ./package/mpmath-1.3.0-py3-none-any.whl\n",
      "Processing ./package/networkx-3.4.2-py3-none-any.whl\n",
      "Processing ./package/numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "Processing ./package/packaging-24.1-py3-none-any.whl\n",
      "Processing ./package/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Processing ./package/regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Processing ./package/requests-2.32.3-py3-none-any.whl\n",
      "Processing ./package/safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Processing ./package/sympy-1.13.1-py3-none-any.whl\n",
      "Processing ./package/tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Processing ./package/torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl\n",
      "Processing ./package/tqdm-4.66.6-py3-none-any.whl\n",
      "Processing ./package/transformers-4.46.1-py3-none-any.whl\n",
      "Processing ./package/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Processing ./package/typing_extensions-4.12.2-py3-none-any.whl\n",
      "Processing ./package/urllib3-2.2.3-py3-none-any.whl\n",
      "certifi is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "charset-normalizer is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "idna is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "numpy is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "packaging is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "requests is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "tqdm is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "typing-extensions is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "urllib3 is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Installing collected packages: mpmath, sympy, safetensors, regex, PyYAML, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, huggingface-hub, torch, tokenizers, transformers\n",
      "Successfully installed MarkupSafe-3.0.2 PyYAML-6.0.2 filelock-3.16.1 fsspec-2024.10.0 huggingface-hub-0.26.2 jinja2-3.1.4 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 regex-2024.9.11 safetensors-0.4.5 sympy-1.13.1 tokenizers-0.20.1 torch-2.5.1 transformers-4.46.1 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ./package/*.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 31/78806 [00:07<5:02:51,  4.34it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in output_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 31/78806 [00:39<27:39:49,  1.26s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Đường dẫn tới video của bạn\n",
    "video_path = \"video.mp4\"\n",
    "audio_output_path = \"output_audio.wav\"\n",
    "\n",
    "# Tách âm thanh từ video\n",
    "video_clip = VideoFileClip(video_path)\n",
    "audio_clip = video_clip.audio\n",
    "audio_clip.write_audiofile(audio_output_path, codec=\"pcm_s16le\")  # Lưu âm thanh dưới định dạng WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/code/video2videosub/.venv_/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of Speech2TextForConditionalGeneration were not initialized from the model checkpoint at facebook/s2t-small-librispeech-asr and are newly initialized: ['model.decoder.embed_positions.weights', 'model.encoder.embed_positions.weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtitles saved as output_subtitles.srt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "import srt\n",
    "from datetime import timedelta\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Check if a GPU is available and move the model to GPU if possible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the model and processor\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\").to(device)\n",
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "\n",
    "# Load and resample the audio file to 16,000 Hz\n",
    "audio_path = \"output_audio.wav\"  # Replace with your file path\n",
    "waveform, sample_rate = torchaudio.load(audio_path)\n",
    "if sample_rate != 16000:\n",
    "    waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)\n",
    "\n",
    "# Define chunk size (e.g., 11 seconds per chunk) and prepare for transcription\n",
    "chunk_size = 11 * 16000  # 11 seconds * 16000 samples per second\n",
    "transcriptions = []\n",
    "\n",
    "# Process each chunk separately and record start/end times for SRT\n",
    "segments = []\n",
    "for i in range(0, waveform.size(1), chunk_size):\n",
    "    # Extract chunk of the waveform\n",
    "    chunk = waveform[:, i:i + chunk_size]\n",
    "\n",
    "    # Preprocess the audio chunk\n",
    "    inputs = processor(chunk.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Perform inference on the chunk\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            inputs[\"input_features\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=200,  # Adjust based on your VRAM availability\n",
    "            num_beams=1\n",
    "        )\n",
    "\n",
    "    # Decode the chunk transcription\n",
    "    transcription_chunk = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    transcriptions.append(transcription_chunk)  # Append the text result for the chunk\n",
    "\n",
    "    # Calculate start and end times for SRT\n",
    "    start_time = timedelta(seconds=i / 16000)\n",
    "    end_time = timedelta(seconds=min(i + chunk_size, waveform.size(1)) / 16000)\n",
    "    segments.append(srt.Subtitle(index=len(segments) + 1, start=start_time, end=end_time, content=transcription_chunk))\n",
    "\n",
    "    # Clear memory after each chunk\n",
    "    del inputs, generated_ids\n",
    "    torch.cuda.empty_cache() if device == \"cuda\" else None\n",
    "\n",
    "# Combine all transcriptions and generate SRT content\n",
    "final_transcription = \" \".join(transcriptions)\n",
    "srt_content = srt.compose(segments)\n",
    "\n",
    "# Save the SRT file\n",
    "srt_path = \"output_subtitles.srt\"\n",
    "with open(srt_path, \"w\") as f:\n",
    "    f.write(srt_content)\n",
    "\n",
    "print(\"Subtitles saved as output_subtitles.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "# Integrate subtitles into the video (requires ffmpeg installed)\n",
    "video_path = \"video.mp4\"  # Replace with your video file path\n",
    "output_video_path = \"video_with_subtitles.mp4\"\n",
    "ffmpeg_command = f\"ffmpeg -i {video_path} -vf subtitles={srt_path} {output_video_path}\"\n",
    "\n",
    "import os\n",
    "os.system(ffmpeg_command)\n",
    "\n",
    "print(f\"Final video with subtitles saved as {output_video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
